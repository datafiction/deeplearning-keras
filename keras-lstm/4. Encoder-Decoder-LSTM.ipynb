{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Encoder Decoder LSTM\n",
    "\n",
    "Sequence to sequence prediction problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from random import randint\n",
    "from numpy import array\n",
    "from math import ceil\n",
    "from math import log10\n",
    "from math import sqrt\n",
    "from numpy import argmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate lists of random integers and their sum\n",
    "def random_sum_pairs(n_examples, n_numbers, largest):\n",
    "  X, y = list(), list()\n",
    "  for i in range(n_examples):\n",
    "    in_pattern = [randint(1,largest) for _ in range(n_numbers)]\n",
    "    out_pattern = sum(in_pattern)\n",
    "    X.append(in_pattern)\n",
    "    y.append(out_pattern)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert data to strings\n",
    "def to_string(X, y, n_numbers, largest):\n",
    "  max_length = int(n_numbers * ceil(log10(largest+1)) + n_numbers - 1)\n",
    "  Xstr = list()\n",
    "  for pattern in X:\n",
    "    strp = '+'.join([str(n) for n in pattern])\n",
    "    strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp \n",
    "    Xstr.append(strp)\n",
    "  max_length = int(ceil(log10(n_numbers * (largest+1))))\n",
    "  ystr = list()\n",
    "  for pattern in y:\n",
    "    strp = str(pattern)\n",
    "    strp = ''.join([' ' for _ in range(max_length-len(strp))]) + strp \n",
    "    ystr.append(strp)\n",
    "  return Xstr, ystr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# integer encode strings\n",
    "def integer_encode(X, y, alphabet):\n",
    "  char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "  Xenc = list()\n",
    "  for pattern in X:\n",
    "    integer_encoded = [char_to_int[char] for char in pattern]\n",
    "    Xenc.append(integer_encoded)\n",
    "  yenc = list()\n",
    "  for pattern in y:\n",
    "    integer_encoded = [char_to_int[char] for char in pattern]\n",
    "    yenc.append(integer_encoded)\n",
    "  return Xenc, yenc\n",
    "                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode\n",
    "def one_hot_encode(X, y, max_int):\n",
    "  Xenc = list()\n",
    "  for seq in X:\n",
    "    pattern = list()\n",
    "    for index in seq:\n",
    "     vector = [0 for _ in range(max_int)]\n",
    "     vector[index] = 1\n",
    "     pattern.append(vector)\n",
    "    Xenc.append(pattern)\n",
    "  yenc = list()\n",
    "  for seq in y:\n",
    "    pattern = list()\n",
    "    for index in seq:\n",
    "     vector = [0 for _ in range(max_int)]\n",
    "     vector[index] = 1\n",
    "     pattern.append(vector)\n",
    "    yenc.append(pattern)\n",
    "  return Xenc, yenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate an encoded dataset\n",
    "def generate_data(n_samples, n_numbers, largest, alphabet):\n",
    "  # generate pairs\n",
    "  X, y = random_sum_pairs(n_samples, n_numbers, largest)\n",
    "  # convert to strings\n",
    "  X, y = to_string(X, y, n_numbers, largest)\n",
    "  # integer encode\n",
    "  X, y = integer_encode(X, y, alphabet)\n",
    "  # one hot encode\n",
    "  X, y = one_hot_encode(X, y, len(alphabet))\n",
    "  # return as numpy arrays\n",
    "  X, y = array(X), array(y)\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# invert encoding\n",
    "def invert(seq, alphabet):\n",
    "  int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "  strings = list()\n",
    "  for pattern in seq:\n",
    "    string = int_to_char[argmax(pattern)]\n",
    "    strings.append(string) \n",
    "  return ''.join(strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# configure problem\n",
    "# number of math terms\n",
    "n_terms = 3\n",
    "# largest value for any single input digit\n",
    "largest = 10\n",
    "# scope of possible symbols for each input or output time step\n",
    "alphabet = [str(x) for x in range(10)] + ['+', ' ']\n",
    "# size of alphabet: (12 for 0-9, + and ' ')\n",
    "n_chars = len(alphabet)\n",
    "# length of encoded input sequence (8 for '10+10+10)\n",
    "n_in_seq_length = int(n_terms * ceil(log10(largest+1)) + n_terms - 1) \n",
    "# length of encoded output sequence (2 for '30')\n",
    "n_out_seq_length = int(ceil(log10(n_terms * (largest+1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import RepeatVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 75)                26400     \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 2, 75)             0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 2, 50)             25200     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 2, 12)             612       \n",
      "=================================================================\n",
      "Total params: 52,212\n",
      "Trainable params: 52,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define LSTM\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(75, input_shape=(n_in_seq_length, n_chars))) \n",
    "\n",
    "model.add(RepeatVector(n_out_seq_length))\n",
    "\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "\n",
    "model.add(TimeDistributed(Dense(n_chars, activation='softmax'))) \n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\\\n",
    "              optimizer='adam',\\\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "75000/75000 [==============================] - 64s - loss: 0.7027 - acc: 0.7946    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11d8e8208>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit LSTM\n",
    "X, y = generate_data(75000, n_terms, largest, alphabet)\n",
    "model.fit(X, y, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.158392, Accuracy: 97.500000\n"
     ]
    }
   ],
   "source": [
    "# evaluate LSTM\n",
    "X, y = generate_data(100, n_terms, largest, alphabet) \n",
    "loss, acc = model.evaluate(X, y, verbose=0) \n",
    "print('Loss: %f, Accuracy: %f' % (loss, acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9+1+2 = 12 (expect 12)\n",
      "   4+3+6 = 13 (expect 13)\n",
      "   6+2+3 = 11 (expect 11)\n",
      "   6+1+6 = 13 (expect 13)\n",
      "   3+5+4 = 12 (expect 12)\n",
      "   3+7+1 = 11 (expect 11)\n",
      "   1+9+3 = 13 (expect 13)\n",
      "   8+2+6 = 16 (expect 16)\n",
      "   1+4+5 = 10 (expect 10)\n",
      "  5+10+6 = 21 (expect 21)\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "for _ in range(10):\n",
    "    # generate an input-output pair\n",
    "    X, y = generate_data(1, n_terms, largest, alphabet)\n",
    "    # make prediction\n",
    "    yhat = model.predict(X, verbose=0)\n",
    "    # decode input, expected and predicted\n",
    "    in_seq = invert(X[0], alphabet)\n",
    "    out_seq = invert(y[0], alphabet)\n",
    "    predicted = invert(yhat[0], alphabet)\n",
    "    print('%s = %s (expect %s)' % (in_seq, predicted, out_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
